tmp <- aggregate(create_weekly$Month, list(create_weekly$Year, create_weekly$Month), function(x) {length(x)})
create_weekly$NumWeeks <- tmp[match(paste(create_weekly$Year, create_weekly$Month), paste(tmp[,1], tmp[,2])), 3]
for (i in 1:nrow(create_weekly)) {
if (create_weekly$Decade[i] == 2020) {
weekly_muni[i,] <- monthly_muni[create_weekly$Month[i],] / create_weekly$NumWeeks[i]
} else if (create_weekly$Decade[i] == 2025) {
weekly_muni[i,] <- (monthly_muni[create_weekly$Month[i],] + monthly_muni[create_weekly$Month[i]+12,]) / 2 / create_weekly$NumWeeks[i]
} else if (create_weekly$Decade[i] == 2035) {
weekly_muni[i,] <- (monthly_muni[create_weekly$Month[i]+12,] + monthly_muni[create_weekly$Month[i]+24,]) / 2 / create_weekly$NumWeeks[i]
} else {
weekly_muni[i,] <- monthly_muni[create_weekly$Month[i]+24,] / create_weekly$NumWeeks[i]
}
}
names(weekly_muni) <- colnames(monthly_muni)
weekly_muni$WALST <- 0		# municipal water has gw source
weekly_muni$COLKE <- 0		# municipal water has gw source
#weekly_muni[weekly_muni>0] = 0
######################### Total demands ######################################
row.names(weekly_muni) <- dates
total_demands <- data.frame(matrix(nrow=nrow(weekly_muni), ncol=length(pod_stns), 0))
for (i in 1:length(pod_stns)) {
colnum1 <- which(names(weekly_muni)==pod_stns[i])
colnum2 <- which(names(weekly_demand)==pod_stns[i])
if (length(colnum1)==0) {
total_demands[,i] <- weekly_demand[,colnum2]
} else {
total_demands[,i] <- weekly_demand[,colnum2] + weekly_muni[,colnum1]
}
}
names(total_demands) <- pod_stns
######################### Tributary Curtailment ###############################
SWFraction <- read.table("inputs/miscellaneous/interruptible_sw_fractions.txt", header=T) # fraction of interruptible demand that comes from a surface water source
iflows <- data.frame(matrix(nrow=length(dates), ncol=length(pod_stns), 0))
for(i in 1:length(stn_iflow)) {
col = which(pod_stns==stn_iflow[i])
if(length(col) == 0) {
next
}
iflows[,col] <- get_iflow(dates, stn_iflow[i]) * cfsTOafw
}
names(iflows) <- pod_stns
curtailment <- data.frame(matrix(nrow=length(dates), ncol=length(stn_list), 0))
instream_shortfall <- data.frame(matrix(nrow=length(dates), ncol=length(stn_list), 0))
names(curtailment) <- names(instream_shortfall) <- stn_list
for (st in stn_list) {
print(st)
arg <- as.numeric(apply(cbind(iflows[,st] + total_demands[,st] - weekly_supply[,st], rep(0, length(dates))), 1, max))
curtailment[,st] <- ifelse(arg>0, interruptible_weekly[,st], 0)
remaining_instream <- weekly_supply[,st] - (total_demands[,st] - curtailment[,st])
instream_shortfall[,st] <- iflows[,st] - apply(cbind(remaining_instream, iflows[,st]), 1, min)
}
curtailment_trib <- curtailment
curtailment_trib[,which(!(stn_list %in% trib_names))] <- 0
################## Calculate demands after accounting for curtailment ##############################################
adj_demand = total_demands
for (st in pod_stns) {
if (st %in% stn_list) {
if (!(st %in% SWFraction$Stn_ID)) {
adj_demand[,st] <- total_demands[,st]
} else {
adj_demand[,st] <- total_demands[,st] - curtailment_trib[,st] * SWFraction$Fraction[which(SWFraction$Stn_ID == st)]  ##### We only want to remove the surface water curtailments for input to RColSim
}
} else {
adj_demand[,st] <- total_demands[,st]
}
}
### We need to make additional adjustments to OKANA and WENMO because each have upstream gauges
arg1 <- as.numeric(apply(cbind(iflows$OKANO + total_demands$OKANO + adj_demand$SIMNI - weekly_supply$OKANO, rep(0, length(dates))), 1, max))
curtailment_trib$OKANO <- ifelse(arg1>0, interruptible_weekly$OKANO, 0)
adj_demand$OKANO <- total_demands$OKANO - curtailment_trib$OKANO * SWFraction$Fraction[SWFraction$Stn_ID=="OKANO"]
arg1 <- as.numeric(apply(cbind(iflows$OKANA + total_demands$OKANA + adj_demand$OKANO + adj_demand$SIMNI - weekly_supply$OKANA, rep(0, length(dates))), 1, max))
curtailment_trib$OKANA <- ifelse(arg1>0, interruptible_weekly$OKANA, 0)
adj_demand$OKANA <- total_demands$OKANA - curtailment_trib$OKANA * SWFraction$Fraction[SWFraction$Stn_ID=="OKANA"]
arg2 <- as.numeric(apply(cbind(iflows$WENMO + total_demands$WENMO + adj_demand$WENPE - weekly_supply$WENMO, rep(0, length(dates))), 1, max))
curtailment_trib$WENMO <- ifelse(arg2>0, interruptible_weekly$WENMO, 0)
adj_demand$WENMO <- total_demands$WENMO - curtailment_trib$WENMO * SWFraction$Fraction[SWFraction$Stn_ID=="WENMO"]
print ("done with adj_demand")
######################### Calculate tributary instream flow deficit ##########################################
actual_flow <- data.frame(matrix(nrow=nrow(weekly_supply), ncol=length(stn_list)))
names(actual_flow) <- stn_list
for (st in stn_list) {
if (st == "WENMO") {
remaining_instream <- weekly_supply$WENMO - total_demands$WENMO - total_demands$WENPE
instream_shortfall$WENMO <- iflows$WENMO - apply(cbind(remaining_instream, iflows$WENMO), 1, min)
actual_flow$WENMO <- remaining_instream + curtailment_trib$WENMO * SWFraction$Fraction[SWFraction$Stn_ID=="WENMO"]
} else if (st == "OKANA") {
remaining_instream <- weekly_supply$OKANA - total_demands$OKANA - total_demands$OKANO - total_demands$SIMNI
instream_shortfall$OKANA <- iflows$OKANA - apply(cbind(remaining_instream, iflows$OKANA), 1, min)
actual_flow$OKANA <- remaining_instream + curtailment_trib$OKANA * SWFraction$Fraction[SWFraction$Stn_ID=="OKANA"]
} else {
remaining_instream <- weekly_supply[,st] - total_demands[,st]
instream_shortfall[,i] <- iflows[,st] - apply(cbind(remaining_instream, iflows[,st]), 1, min)
if (st %in% stn_iflow) {
actual_flow[,st] <- remaining_instream + curtailment_trib[,st] * SWFraction$Fraction[SWFraction$Stn_ID==st]
}
}
}
actual_flow <- actual_flow[,which(names(actual_flow) %in% trib_names)]
############################ aggregate the demand aggregation areas to the RColSim drainages ########################
UpSnakeCorrectionFactor <- 1/.65 * 1.25
UpSnakeCorrectionFactor2 <- 1/.75 * 1.25
apply_correction <- c("SNKHI", "MILNE", "PALIS", "HFORK", "IPARK", "SNKHE", "OWYHE", "OWYHE_ID", "AMERI", "MINAD", "RIRDM", "BROWN", "OXBOW", "HCANY", "JLAKE")
apply_correction2 <- c("LUCKY", "LBOIS", "PAYET", "PAYHS")
adj_demand[,apply_correction] <- UpSnakeCorrectionFactor * adj_demand[,apply_correction]
adj_demand[,apply_correction2] <- UpSnakeCorrectionFactor2 * adj_demand[,apply_correction2]
map_stations <- read.csv("inputs/miscellaneous/station_mapping", sep="\t", header=F, stringsAsFactors=F) ## maps the demand drainage areas to the RColSim drainage areas
weekly_demand_agg <- adj_demand[,which(pod_stns %in% stn_colsim)]
new_pod_names <- pod_stns[pod_stns %in% stn_colsim]
for(i in 1:length(new_pod_names)) {
stations_to_sum <- map_stations[map_stations[,1] == new_pod_names[i],2]
weekly_demand_agg[,i] <- apply(as.matrix(adj_demand[,match(stations_to_sum, pod_stns)]), 1, sum)
}
weekly_demand_agg$BoiseSys <- adj_demand$LBOIS         ## Demand for the Boise River system
weekly_demand_agg$Minidoka <- adj_demand$MINAD + adj_demand$MILNE + adj_demand$SNKHI   ## Demand for the Minidoka project
weekly_demand_agg$Owyhee <- adj_demand$OWYHE_ID ## Demand for Owyhee Irrigation District
weekly_demand_agg$UpSnake <- adj_demand$AMERI + adj_demand$RIRDM ## Demand for UpperSnake system
weekly_demand_agg$Payette <- adj_demand$PAYET ## Demand for Payette system
weekly_demand_agg$SNKHE <- adj_demand$SNKHE
weekly_demand_agg$HFORK <- adj_demand$HFORK
weekly_demand_agg$LIMEP <- adj_demand$LIMEP
}
#################### Write Output #################################
final_weekly_supply <- data.frame(matrix(nrow=nrow(weekly_supply), ncol=length(stn_colsim)))
for (ii_s in 1:length(stn_colsim)) {
col_nu <- which(stn_list==stn_colsim[ii_s])
final_weekly_supply[,ii_s] <- weekly_supply[,col_nu]
}
names(final_weekly_supply) <- stn_colsim
final_weekly_supply$SNKHE <- weekly_supply$SNKHE
final_weekly_supply$OXBOW <- weekly_supply$BROWN
final_weekly_supply$HFORK <- weekly_supply$HFORK
final_weekly_supply$LIMEP <- weekly_supply$LIMEP
if (scr_name == "Historical_baseline/baseline") {
timeseries <- read.table("inputs/miscellaneous/ts_historical.txt", header=T)
} else if (length(grep("hist", scr_name)) == 1) {
timeseries <- read.table("inputs/miscellaneous/ts_hist.txt", header=T)
} else {
timeseries <- read.table("inputs/miscellaneous/ts_GCM.txt", header=T)
}
outdir <- paste0("inputs/Preliminary/output/", run_type, "/", strsplit(scr_name, "/")[[1]][1])
if (!dir.exists(outdir)) { dir.create(outdir, recursive=T) }
setwd(outdir)
supply <- cbind(timeseries, final_weekly_supply[start_index:end_index,])
write.table(supply, file=paste0("supply_", strsplit(scr_name, "/")[[1]][2],  ".txt"), row.names=F)
if (run_type == "supply_and_demand") {
demand <- cbind(timeseries, data.frame(weekly_demand_agg[start_index:end_index,]))
iflow <- cbind(timeseries, iflows[start_index:end_index,which(names(iflows) %in% mainstem_names)])
interruptible <- cbind(timeseries, data.frame(interruptible_weekly[start_index:end_index, which(names(interruptible_weekly) %in% mainstem_names)]))
names(demand)[1:4] <- names(iflow)[1:4] <- names(interruptible)[1:4] <- c("Week", "Month", "Day", "Year")
write.table(iflow, file=paste0("iflow_", strsplit(scr_name, "/")[[1]][2], ".txt"), row.names=F)
write.table(interruptible, file=paste0("interruptible_", strsplit(scr_name, "/")[[1]][2], ".txt"), row.names=F)
write.table(demand, file=paste0("demand_", strsplit(scr_name, "/")[[1]][2], ".txt"), row.names=F)
}
scr_name="Historical_baseline"
scr_name <- gsub("_", "/", scr_name)
run_type="supply_and_demand"
source("scripts/load_functions_input_file.R")
getwd()
setwd("~/RColSimV2/RColSim")
source("scripts/load_functions_input_file.R")
source("scripts/load_functions.R")
source("scripts/read_rule_curves.R")
Read_Rule_Curves()
if(scr_name == "Historical/baseline") {
scr_name <- "Historical_baseline/baseline"
}
if (run_type == "supply_and_demand") {
simulate_demand <- 1
} else {
simulate_demand <- 0
}
gcm <- strsplit(scr_name, "/")[[1]][1] ## The global circulation model, if future climate data are used, or Historical_baseline for historical climate data
scr <- strsplit(scr_name, "/")[[1]][2]
gcm <- strsplit(scr_name, "/")[[1]][1] ## The global circulation model, if future climate data are used, or Historical_baseline for historical climate data
scr <- strsplit(scr_name, "/")[[1]][2] ## rcp4.5 or rcp8.5 for future climate scenarios
indir <- "inputs/"
indir2 <- paste0("inputs/Preliminary/output/", run_type, "/", gcm, "/")
indr2
indir2
stn_colsim <- read.table(paste0("inputs/miscellaneous/RColSim_stations.txt"), header=T, stringsAsFactors=F)
DamMaxMin <- read.table(paste0(indir, "miscellaneous/DamMaxMin.txt"), header=T)
mainstem_names <- c("CHIEF", "DALLE", "JDAYY", "MCNAR", "PRIRA", "ROCKY", "RISLA", "WANAP", "WELLS") ## Dams along the Columbia mainstem
ListOfDams <- c("MICAA", "ARROW", "DUNCA", "DWORS", "GCOUL", "FLASF", "LIBBY", "BROWN", "ALBEN", "FLAPO", "CORRA") # List of storage reservoirs for which to compute variable refill curves
dam_lookup <- data.frame(name1=ListOfDams, name2=c("Mica", "Arrow", "Duncan", "Dworshak", "GrandCoulee",
"HungryHorse", "Libby", "Brownlee", "AF", "Kerr", "CL"), name3=c("MI", "AR", "DU", "DW", "GC", "HH",
"LB", "BR", "AF", "KE", "CL"), stringsAsFactors=F)
cfsTOafw <- 1.9834 * 7 ## cubic feet per second to acre-feet per week conversion
Supply_Input <- read.table(paste0(indir2, "supply_", scr, ".txt"), header=T)
if (scr_name == "Historical_baseline/baseline") {
N <- tail(which(Supply_Input$Month == 9 & Supply_Input$Year == 2007), 1) ## Number of timesteps. We stop at 2007 because the historical climate inputs for Canadian portion of the CRB are erroneous.
} else {
N <- nrow(Supply_Input)
}
sim_end_date <- as.Date(paste(Supply_Input$Month, Supply_Input$Day, Supply_Input$Year, sep="/"), "%m/%d/%Y")[N]
Supply_Input <- Supply_Input[1:N,]
names(Supply_Input)[1:4] <- c("Week", "Month", "Day", "Year")
timeseries <- Supply_Input[1:4]
begin_year <- min(timeseries$Year)
n_years <- length(unique(Supply_Input$Year)) - 1
sim_start_year <- unique(Supply_Input$Year)[1]
if (simulate_demand == 1) {
Demand_Input <- read.table(paste0(indir2, "demand_", scr, ".txt"), header=T)[1:N,] ## Surface water irrigation and municipal demand
interruptible_demand <- read.table(paste0(indir2, "/interruptible_", scr, ".txt", sep=""), header=T)[1:N,] ## Water demand from interruptible water rights along the Columbia mainstem
} else {
Demand_Input <- data.frame(matrix(nrow=N, ncol=nrow(stn_colsim)+9, 0)) ## Replace with zeros if want to run without withdrawals
interruptible_demand <- data.frame(matrix(nrow=N, ncol=length(mainstem_names) + 4, 0))
}
if (simulate_demand == 1) {
flow_map <- read.table(paste0("inputs/miscellaneous/modified_flow_map.txt"), header=T, stringsAsFactors=F) # Upstream/downstream position of stream gages at which flow inputs are measured
mod_flow_list <- names(Supply_Input)[-c(1:4)]
modified_flow <- data.frame(matrix(nrow=nrow(Supply_Input), ncol=length(mod_flow_list) + 4))
modified_flow[1:4] <- timeseries
names(modified_flow) <- c(names(timeseries), mod_flow_list)
for (dam in mod_flow_list) {
col_names <- get_columns(dam, flow_map)
up_demand <- apply(Demand_Input[col_names], 1, sum) ## Total upstream demand
modified_flow[dam] <- Supply_Input[,dam] - up_demand
}
} else {
modified_flow <- Supply_Input
}
head(modified_flow)
if (simulate_demand == 1) {
supply_for_return_flow <- data.frame(matrix(nrow=N, ncol=7, 0))
supply_for_return_flow[,1:4] <- timeseries
supply_for_return_flow_locs <- c("WANAP", "PRIRA", "MCNAR")
for (i in 1:3) {
col <- which(names(modified_flow) == supply_for_return_flow_locs[i])
supply_for_return_flow[,i+4] <- modified_flow[,col]
}
names(supply_for_return_flow) <- c("Week", "Month", "Day", "Year", supply_for_return_flow_locs)
return_fractions <- read.csv(paste0("inputs/miscellaneous/return_flow_fractions.csv"), header=T)[,-1] # these fractions were derived from the document, "Calculation of 2020 Irrigation Depletions for
# 2020 Level Modified Streamsflows, Hills et al., prepared for BPA, 2020.
} else {
return_fractions <- data.frame(matrix(nrow=N, ncol=3, 0))
supply_for_return_flow <- data.frame(matrix(nrow=N, ncol=7, 0))
}
refill_names <- c("AR", "DU", "DW", "GC", "HH", "LB", "MI")
min_refill_names <- c("AF", "AR", "BR", "CL", "DU", "DW", "GC", "HH", "LB", "MI", "KE")
Dem_list <- c("BoiseSys", "Minidoka", "Owyhee", "Payette", "UpSnake", stn_colsim[match(mainstem_names, stn_colsim[,1]),2])
names_Output <- c("Week", "Month", "Day", "Year", "BRRunoffAprJul", "DARunoffAprAug", "DARunoffAprSep", "DARunoffJanJul", "DURunoffAprAug", "DWRunoffAprJul", "HHRunoffAprAug", "HHRunoffMaySep",
"LBRunoffAprAug", "LGRunoffAprJul", "MIRunoffAprAug", "MIRunoffMayAug", "PayetteResidualInflowJanJun", "OwyheeResidualInflowJanMay", "BoiseResidualInflowJanJul", "HeiseResidualInflowJanJul",
"HenryResidualInflowJanJun", "RirieResidualInflowJanJun", "PRResidualInflowJanMar", "GCResidualInflowJanMar", "RetWA", "RetPR", "RetMCN", paste0(refill_names, "VariableRefillCurve"),
paste0(min_refill_names, "MinRefillCurve"), paste0(min_refill_names, "OperatingRuleCurve"), paste0("Flow", c("LimePoint", stn_colsim[,2])), paste0("Dem", Dem_list),
paste0("Curt", stn_colsim[match(mainstem_names, stn_colsim[,1]),2]), paste0("Iflow", stn_colsim[match(mainstem_names, stn_colsim[,1]),2]), "CorrectedDARunoffAprAug",
"InitialControlledFlow", "start_refill_wk", "start_refill_wk_GC", "DACorrectedResidualInflowAprAug")
Output_to_ColSim <- data.frame(matrix(ncol=length(names_Output), nrow=N))
Output_to_ColSim[1:4] <- timeseries
names(Output_to_ColSim) <- names_Output
refill_option <- 1
if (refill_option == 1) {
PDR_80 <- read.table(paste0(indir, "assumed_release/AssumedRelease_80MAF_2018.txt"), header=T)
PDR_95 <- read.table(paste0(indir, "assumed_release/AssumedRelease_95MAF_2018.txt"), header=T)
PDR_110 <- read.table(paste0(indir, "assumed_release/AssumedRelease_110MAF_2018.txt"), header=T)
forecast_error <- read.table(paste0("inputs/miscellaneous/Forecast_errors.txt"), header=T)
} else if (refill_option == 2) {
PDR_80 <- read.table(paste0(indir, "assumed_release/AssumedRelease_80MAF_PF.txt"), header=T)
PDR_95 <- read.table(paste0(indir, "assumed_release/AssumedRelease_95MAF_PF.txt"), header=T)
PDR_110 <- read.table(paste0(indir, "assumed_release/AssumedRelease_110MAF_PF.txt"), header=T)
forecast_error <- read.table(paste0("inputs/miscellaneous/Forecast_errors_PF.txt"), header=T)
}
PDR_lower <- read.table(paste0(indir, "assumed_release/AssumedRelease_min.txt"), header=T) ## assume minimum project outflows
target_refill_week <- data.frame(Dam=ListOfDams, Week=c(52, 52, 52, 48, 48, 48, 48, 48, 52, 52, 5))
July31s <- data.frame(matrix(nrow=n_years, ncol=length(ListOfDams))) ## the target refill week for each year
nws <- data.frame(matrix(nrow=n_years, ncol=length(ListOfDams))) ## number of weeks in each year (52 or 53, depending on whether it is a leap year)
names(July31s) <- ListOfDams
names(nws) <- ListOfDams
for (d in ListOfDams) {
wk <- target_refill_week$Week[target_refill_week$Dam==d]
if (wk == 52) {
July31s[d] <- (which(timeseries$Month == 8 & timeseries$Week == 1) - 1)[-1]
} else if (wk > 40) {
July31s[d] <- which(timeseries$Week == wk)
} else {
July31s[d] <- which(timeseries$Week == wk)[-1]
}
nws[d] <- c(52, July31s[,d][2:length(July31s[,d])] - July31s[,d][1:(length(July31s[,d])-1)])
}
Output_to_ColSim$DARunoffJanJul[1:n_years] <- subset(aggregate(modified_flow$DALLE, list(modified_flow$Year, modified_flow$Month<=7), sum), Group.2 == TRUE & Group.1 > begin_year)[,3]
Output_to_ColSim$DARunoffAprAug[1:n_years] <- subset(aggregate(modified_flow$DALLE, list(modified_flow$Year, modified_flow$Month %in% 4:8), sum), Group.2 == TRUE & Group.1 > begin_year)[,3]
Output_to_ColSim$DARunoffAprSep[1:n_years] <- subset(aggregate(modified_flow$DALLE, list(modified_flow$Year, modified_flow$Month %in% 4:9), sum), Group.2 == TRUE & Group.1 > begin_year)[,3]
Output_to_ColSim$DURunoffAprAug[1:n_years] <- subset(aggregate(modified_flow$DUNCA, list(modified_flow$Year, modified_flow$Month %in% 4:8), sum), Group.2 == TRUE & Group.1 > begin_year)[,3]
Output_to_ColSim$DWRunoffAprJul[1:n_years] <- subset(aggregate(modified_flow$DWORS, list(modified_flow$Year, modified_flow$Month %in% 4:7), sum), Group.2 == TRUE & Group.1 > begin_year)[,3]
Output_to_ColSim$BRRunoffAprJul[1:n_years] <- subset(aggregate(modified_flow$BROWN, list(modified_flow$Year, modified_flow$Month %in% 4:7), sum), Group.2 == TRUE & Group.1 > begin_year)[,3]
Output_to_ColSim$LGRunoffAprJul[1:n_years] <- subset(aggregate(modified_flow$LGRAN, list(modified_flow$Year, modified_flow$Month %in% 4:7), sum), Group.2 == TRUE & Group.1 > begin_year)[,3]
Output_to_ColSim$HHRunoffAprAug[1:n_years] <- subset(aggregate(modified_flow$FLASF, list(modified_flow$Year, modified_flow$Month %in% 4:7), sum), Group.2 == TRUE & Group.1 > begin_year)[,3]
Output_to_ColSim$HHRunoffMaySep[1:n_years] <- subset(aggregate(modified_flow$FLASF, list(modified_flow$Year, modified_flow$Month %in% 5:9), sum), Group.2 == TRUE & Group.1 > begin_year)[,3]
Output_to_ColSim$LBRunoffAprAug[1:n_years] <- subset(aggregate(modified_flow$LIBBY, list(modified_flow$Year, modified_flow$Month %in% 4:8), sum), Group.2 == TRUE & Group.1 > begin_year)[,3]
Output_to_ColSim$MIRunoffAprAug[1:n_years] <- subset(aggregate(modified_flow$MICAA, list(modified_flow$Year, modified_flow$Month %in% 4:8), sum), Group.2 == TRUE & Group.1 > begin_year)[,3]
Output_to_ColSim$MIRunoffMayAug[1:n_years] <- subset(aggregate(modified_flow$MICAA, list(modified_flow$Year, modified_flow$Month %in% 5:8), sum), Group.2 == TRUE & Group.1 > begin_year)[,3]
DA_forecast <- data.frame(unique(timeseries$Year)[-1], Output_to_ColSim$DARunoffJanJul[1:n_years])
names(DA_forecast) <- c("Year", "Q")
years <- DA_forecast$Year
VariableRefillCurve <- calc_refill_curve("regular") ## Normal refill curve, function called from LoadFunctions_input_file.R
head(VariableRefillCurve)
for (d in c("MI", "DU", "LB", "HH", "KE", "AF", "CL", "BR", "DW")) {
dam <- dam_lookup$name1[dam_lookup$name3 == d]
assign(paste0(d, "Refill_min"), VariableRefillCurve_min[2:N,dam] - VariableRefillCurve_min[1:(N-1),dam]) ## Refill requirement for each timestep to meet target refill
}
VariableRefillCurve_min <- calc_refill_curve("minimum") ## Perfect Forecast refill curve
for (d in c("MI", "DU", "LB", "HH", "KE", "AF", "CL", "BR", "DW")) {
dam <- dam_lookup$name1[dam_lookup$name3 == d]
assign(paste0(d, "Refill_min"), VariableRefillCurve_min[2:N,dam] - VariableRefillCurve_min[1:(N-1),dam]) ## Refill requirement for each timestep to meet target refill
}
source("scripts/load_functions_input_file.R")
source("scripts/load_functions.R")
source("scripts/read_rule_curves.R")
MIRuleCurves.df <- RuleCurve_df("MICAA") ## function called from LoadFunctions_input_file.R
head(MIRuleCurves.df)
ARRuleCurves.df <- RuleCurve_df("ARROW")
DURuleCurves.df <- RuleCurve_df("DUNCA")
LBRuleCurves.df <- RuleCurve_df("LIBBY")
HHRuleCurves.df <- RuleCurve_df("FLASF")
KERuleCurves.df <- RuleCurve_df("FLAPO")
AFRuleCurves.df <- RuleCurve_df("ALBEN")
CLRuleCurves.df <- RuleCurve_df("CORRA")
BRRuleCurves.df <- RuleCurve_df("BROWN")
DWRuleCurves.df <- RuleCurve_df("DWORS")
VariableRefillCurve$ARROW <- calc_refill_with_upstream_storage("regular", "ARROW") ## function called from LoadFunctions_input_file.R
VariableRefillCurve_min$ARROW <- calc_refill_with_upstream_storage("minimum", "ARROW")
ARRuleCurves.df <- RuleCurve_df("ARROW") ## Calculate rule curves for ARROW, including normal operation refill requirement
ARRefill_min <- VariableRefillCurve_min$ARROW[2:N] - VariableRefillCurve_min$ARROW[1:(N-1)] ## Perfect forecast refill requirement for ARROW
GCUpstreamRefill <- MIRuleCurves.df$RefillReq + ARRuleCurves.df$RefillReq + DURuleCurves.df$RefillReq +
LBRuleCurves.df$RefillReq + HHRuleCurves.df$RefillReq + KERuleCurves.df$RefillReq +
AFRuleCurves.df$RefillReq + CLRuleCurves.df$RefillReq + DWRuleCurves.df$RefillReq
GCUpstreamRefill[is.na(GCUpstreamRefill)] <- 0
GCUpstreamRefill_min <- MIRefill_min + ARRefill_min + DURefill_min + LBRefill_min + HHRefill_min + KERefill_min +
AFRefill_min + CLRefill_min + DWRefill_min
GCUpstreamRefill_min[is.na(GCUpstreamRefill_min)] <- 0
VariableRefillCurve$GCOUL <- calc_refill_with_upstream_storage("regular", "GCOUL")
VariableRefillCurve_min$GCOUL <- calc_refill_with_upstream_storage("minimum", "GCOUL")
OperatingRuleCurves.df <- data.frame(matrix(nrow=N, ncol=ncol(VariableRefillCurve)))
OperatingRuleCurves.df[1:3] <- VariableRefillCurve[1:3]
names(OperatingRuleCurves.df) <- c("Week", "Month", "Year", "MICAA", "ARROW", "DUNCA", "DWORS", "FLASF",
"LIBBY", "ALBEN", "FLAPO", "CORRA", "BROWN", "GCOUL")
OperatingRuleCurves.df$MICAA <- MIRuleCurves.df$OperatingRuleCurve
OperatingRuleCurves.df$ARROW <- ARRuleCurves.df$OperatingRuleCurve
OperatingRuleCurves.df$DUNCA <- DURuleCurves.df$OperatingRuleCurve
OperatingRuleCurves.df$DWORS <- DWRuleCurves.df$OperatingRuleCurve
OperatingRuleCurves.df$FLASF <- HHRuleCurves.df$OperatingRuleCurve
OperatingRuleCurves.df$LIBBY <- LBRuleCurves.df$OperatingRuleCurve
OperatingRuleCurves.df$ALBEN <- AFRuleCurves.df$OperatingRuleCurve
OperatingRuleCurves.df$FLAPO <- KERuleCurves.df$OperatingRuleCurve
OperatingRuleCurves.df$CORRA <- CLRuleCurves.df$OperatingRuleCurve
OperatingRuleCurves.df$BROWN <- BRRuleCurves.df$OperatingRuleCurve
Mar_31s <- which(Output_to_ColSim$Week == 35)
AprilDAUpstreamStorageGC <- pmin(4.08e6, MIFullPoolVol - MIRuleCurves.df$OperatingRuleCurve[Mar_31s]) +
pmin(3.6e6, ARFullPoolVol - ARRuleCurves.df$OperatingRuleCurve[Mar_31s]) + (LBFullPoolVol - LBRuleCurves.df$OperatingRuleCurve[Mar_31s]) +
(HHFullPoolVol - HHRuleCurves.df$OperatingRuleCurve[Mar_31s]) + (DUFullPoolVol - DURuleCurves.df$OperatingRuleCurve[Mar_31s]) +
(DWFullPoolVol - DWRuleCurves.df$OperatingRuleCurve[Mar_31s]) + (BRFullPoolVol - BRRuleCurves.df$OperatingRuleCurve[Mar_31s]) +
(CLFullPoolVol - CLRuleCurves.df$OperatingRuleCurve[Mar_31s]) + (KEFullPoolVol - KERuleCurves.df$OperatingRuleCurve[Mar_31s]) +
(AFFullPoolVol - AFRuleCurves.df$OperatingRuleCurve[Mar_31s])
Output_to_ColSim$CorrectedDARunoffAprAug <- Output_to_ColSim$DARunoffAprAug - c(AprilDAUpstreamStorageGC, rep(NA, N - n_years))
GCRuleCurves.df <- RuleCurve_df("GCOUL")
OperatingRuleCurves.df$GCOUL <- GCRuleCurves.df$Flood
write.table(OperatingRuleCurves.df, "inputs/Preliminary/OperatingRuleCurves.txt", row.names=F, col.names=T, quote=F) ## These are preliminary. The actual operating rule curves may change once the actual dam inflows are computed at runtime by the main program.
full_pool <- c(MICAA=MIFullPoolVol, ARROW=ARFullPoolVol, LIBBY=LBFullPoolVol, FLASF=HHFullPoolVol, DUNCA=DUFullPoolVol, DWORS=DWFullPoolVol, BROWN=BRFullPoolVol, GCOUL=GCFullPoolVol, FLAPO=KEFullPoolVol, ALBEN=AFFullPoolVol, CORRA=CLFullPoolVol)
min_storage <- c(MICAA=4.08e6, ARROW=3.6e6, LIBBY=4.98e6, FLASF=3.07e6, DUNCA=1.27e6, DWORS=2015200, BROWN=975000, GCOUL=5.19e6, FLAPO=1.22e6, CORRA=6.72e6, ALBEN=1.12e6)
Dams <- c("MICAA", "ARROW", "LIBBY", "FLASF", "DUNCA", "DWORS" , "BROWN", "GCOUL")
DAUpStreamStorage <- data.frame(matrix(nrow=N, ncol=length(Dams) + 4, 0))
DAUpStreamStorage[1:4] <- modified_flow[1:4]
names(DAUpStreamStorage) = c("Week", "Month", "Day", "Year", Dams)
for (res in Dams) {
DAUpStreamStorage[,res] <- pmin(min_storage[res], full_pool[res] - OperatingRuleCurves.df[,res])
}
DAUpStreamStorage$Sum <- apply(DAUpStreamStorage[-c(1:4)], 1, sum)
Output_to_ColSim$DACorrectedResidualInflowAprAug <- DAResidualInflow(DAUpStreamStorage) ## Function called from (LoadFunctions_input_file.R)
ICF_table <- read.table("inputs/default_rule_curves/Dalles_ICF.txt", header=T) ## Chart 1 from Columbia River Treaty Flood Control Operating Plan (FCOP) (2003)
flow_inc <- seq(from=30e6, to=140e6, by=5e6)
Output_to_ColSim$InitialControlledFlow <- sapply(1:N, function(x) get_ICF(Output_to_ColSim$DACorrectedResidualInflowAprAug[x], timeseries$Week[x]))  ## Function called from (LoadFunctions_input_file.R)
## Refill period begins three weeks before the unregulated flow at The Dalles is forecasted to exceed 450,000 cfs (FCOP, 2003)
Output_to_ColSim$start_refill_wk[1:n_years] <- aggregate(modified_flow$DALLE, list(modified_flow$Year), function(x) which(x > 450000 * cfsTOafw)[1] - 3 + 22)[-1,2] ## the +22 converts from a calendar to year to a year beginning on Aug. 1
start_refill_wk_GC = vector()
for (y in 1:length(years)) {
ICF <- subset(Output_to_ColSim, Year == years[y] & Week == Output_to_ColSim$start_refill_wk[y])$InitialControlledFlow
wk_GC <- which(subset(modified_flow, Year == years[y])$DALLE >= ICF * cfsTOafw)[1] + 22
start_refill_wk_GC <- c(start_refill_wk_GC, wk_GC)
}
Output_to_ColSim$start_refill_wk_GC <- c(start_refill_wk_GC, rep(NA, N - n_years))
Output_to_ColSim$HeiseResidualInflowJanJul <- runoff_remaining("SNKHE", 23, 50, modified_flow) # Residual inflow for Palisades and Jackson Lake rule curves
Output_to_ColSim$HenryResidualInflowJanJun <- runoff_remaining("IPARK", 23, 47, modified_flow) # Residual inflow for Island Park rule curve
Output_to_ColSim$RirieResidualInflowJanJun <- runoff_remaining("RIRDM", 23, 47, modified_flow) # Residual inflow for Ririe rule curve
Output_to_ColSim$BoiseResidualInflowJanJul <- runoff_remaining("LUCKY", 23, 49, modified_flow) # Residual inflow for Boise system rule curve
Output_to_ColSim$OwyheeResidualInflowJanMay <- runoff_remaining("OWYHE", 23, 45, modified_flow) # Residual inflow for Owyhee rule curve
Output_to_ColSim$PayetteResidualInflowJanJun <- runoff_remaining("PAYHS", 23, 47, modified_flow) # Residual inflow for Payette system rule curve
## Residual inflow to Priest Rapids dam for computation of Grand Coulee variable draft limit
## Currently in the model historical probable inflows are used rather than forecasted inflows.
Output_to_ColSim$PRResidualInflowJanMar <- runoff_remaining("PRIRA", 23, 36, modified_flow)
Output_to_ColSim$GCResidualInflowJanMar <- runoff_remaining("GCOUL", 23, 36, modified_flow)
variable_refill_list <- c("MICAA", "ARROW", "DUNCA", "LIBBY", "FLASF", "DWORS", "GCOUL")
for (res in variable_refill_list) {
abbrev <- paste0(stn_colsim[which(stn_colsim[,1]==res),2])
var <- paste0(abbrev, "VariableRefillCurve")
Output_to_ColSim[,var] <- VariableRefillCurve[,res]
}
for (res in ListOfDams) {
abbrev <- paste0(stn_colsim[which(stn_colsim[,1]==res),2])
var1 <- paste0(abbrev, "MinRefillCurve")
var2 <- paste0(abbrev, "FloodCurve")
Output_to_ColSim[,var1] <- VariableRefillCurve_min[,res]
}
for (res in names(OperatingRuleCurves.df)[-c(1:3)]) {
abbrev <- paste0(stn_colsim[which(stn_colsim[,1]==res),2])
var <- paste0(abbrev, "OperatingRuleCurve")
Output_to_ColSim[,var] <- OperatingRuleCurves.df[,res]
}
flow_list <- c(stn_colsim[,1], "LimePoint")
for (loc in flow_list) {
abbrev <- ifelse(loc=="LimePoint", "LimePoint", stn_colsim[which(stn_colsim[,1]==loc),2])
loc <- ifelse(loc=="LimePoint", "LIMEP", loc)
var_supply <- paste0("Flow", abbrev)
Output_to_ColSim[,var_supply] <- modified_flow[,loc]
}
demand_list = c("BoiseSys", "Minidoka", "Owyhee", "Payette", "UpSnake", mainstem_names) ## irrigation demands for Upper Snake River irrigation districts
for (dem in demand_list) {
abbrev <- ifelse(dem %in% mainstem_names, stn_colsim[which(stn_colsim[,1]==dem),2], dem)
var_demand <- paste0("Dem", abbrev)
if (simulate_demand == 1) {
Output_to_ColSim[,var_demand] <- Demand_Input[,dem]
} else {
Output_to_ColSim[,var_demand] <- rep(0, nrow(Output_to_ColSim))
}
}
for (m in mainstem_names) {
abbrev <- stn_colsim[which(stn_colsim[,1]==m),2]
var_interruptible <- paste0("Curt", abbrev)
var_iflow <- paste0("Iflow", abbrev)
if (simulate_demand == 1) {
Output_to_ColSim[,var_interruptible] <- interruptible_demand[,m]
Output_to_ColSim[,var_iflow] <- get_iflow_mainstem(m)
} else {
Output_to_ColSim[,var_interruptible] <- rep(0, nrow(Output_to_ColSim))
Output_to_ColSim[,var_iflow] <- rep(0, nrow(Output_to_ColSim))
}
}
if (simulate_demand == 1) {
annual_return <- aggregate(supply_for_return_flow[5:7], list(supply_for_return_flow$Year), sum)
Output_to_ColSim$RetWA <- return_fractions$WANAP[match(supply_for_return_flow$Week, 1:52)] * annual_return$WANAP[match(supply_for_return_flow$Year, annual_return[,1])]
Output_to_ColSim$RetPR <- return_fractions$PRIRA[match(supply_for_return_flow$Week, 1:52)] * annual_return$PRIRA[match(supply_for_return_flow$Year, annual_return[,1])]
Output_to_ColSim$RetMCN <- return_fractions$MCNAR[match(supply_for_return_flow$Week, 1:52)] * annual_return$MCNAR[match(supply_for_return_flow$Year, annual_return[,1])]
} else {
Output_to_ColSim$RetWA <- rep(0, nrow(Output_to_ColSim))
Output_to_ColSim$RetPR <- rep(0, nrow(Output_to_ColSim))
Output_to_ColSim$RetMCN <- rep(0, nrow(Output_to_ColSim))
}
indir
Output_to_ColSim$DamYear <- ifelse(Output_to_ColSim$Month >= 8, Output_to_ColSim$Year + 1, Output_to_ColSim$Year)
write.table(Output_to_ColSim, file=paste0(indir, "input_timeseries/ToRColSim_scenario_", scr, "_", run_type, ".txt"), row.names=FALSE)
if (scr_name == "Historical_baseline/baseline") {
global_input_file <- "Historical_baseline"
outdir <- paste0("output/", run_type, "/Historical_baseline/")
} else {
global_input_file <- sub("/", "_", scr_name)
outdir <- paste0("output/", run_type, "/", gcm, "/", scr, "/")
}
if (!dir.exists(outdir)) { dir.create(outdir, recursive=T) }
outdir
if (!dir.exists(outdir)) { dir.create(outdir, recursive=T) }
GIF <- data.frame(matrix(nrow=5, ncol=2))
GIF[,1] <- c("RColSim_WD", "Flow_Input_File", "Output_Folder", "simulation_start_year", "simulation_end_date")
GIF[1,2] <- getwd()
GIF[2,2] <- paste0(indir, "ToRColSim_scenario_", scr, "_", run_type, ".txt")
GIF[3,2] <- outdir
GIF[4,2] <- sim_start_year
GIF[5,2] <- as.character(sim_end_date)
GIF
indir
if (scr_name == "Historical_baseline/baseline") {
global_input_file <- "Historical_baseline"
outdir <- paste0("output/", run_type, "/Historical_baseline/")
} else {
global_input_file <- sub("/", "_", scr_name)
outdir <- paste0("output/", run_type, "/", gcm, "/", scr, "/")
}
if (!dir.exists(outdir)) { dir.create(outdir, recursive=T) }
GIF <- data.frame(matrix(nrow=5, ncol=2))
GIF[,1] <- c("RColSim_WD", "Flow_Input_File", "Output_Folder", "simulation_start_year", "simulation_end_date")
GIF[1,2] <- getwd()
GIF[2,2] <- paste0(indir, "/input_timeseries/ToRColSim_scenario_", scr, "_", run_type, ".txt")
GIF[3,2] <- outdir
GIF[4,2] <- sim_start_year
GIF[5,2] <- as.character(sim_end_date)
GIF
GIF <- data.frame(matrix(nrow=5, ncol=2))
GIF[,1] <- c("RColSim_WD", "Flow_Input_File", "Output_Folder", "simulation_start_year", "simulation_end_date")
GIF[1,2] <- getwd()
GIF[2,2] <- paste0(indir, "input_timeseries/ToRColSim_scenario_", scr, "_", run_type, ".txt")
GIF[3,2] <- outdir
GIF[4,2] <- sim_start_year
GIF[5,2] <- as.character(sim_end_date)
GIF
paste0(indir, "global_input_files/GIF_", global_input_file, "_", run_type)
write.table(GIF, paste0(indir, "global_input_files/GIF_", global_input_file, "_", run_type), col.names=F, row.names=F, quote=T)
library(testthat)
scr <<- "tests_hist"
run_type<<- "supply_and_demand"
# Run RColSim for the test scenarios
# Run the RColSim main code
source("RColSim_main.R")
getwd()
read.table(paste0("inputs/GIF_", scr, "_", run_type), stringsAsFactors=F)
scr
run_type
read.table(paste0("inputs/global_input_files/GIF_", scr, "_", run_type), stringsAsFactors=F)
getwd()
library(testthat)
scr <<- "tests_hist"
run_type<<- "supply_and_demand"
# Run RColSim for the test scenarios
# Run the RColSim main code
source("RColSim_main.R")
getwd()
